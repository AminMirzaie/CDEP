{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f45951e-d2af-4e43-9844-6fb4cf5b2dae",
   "metadata": {},
   "source": [
    "# 00_download_metadata.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a659ab-12e0-4a74-acbf-fe3a1d23ce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "from isic_api import ISICApi\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "from tqdm.autonotebook import tqdm\n",
    "with open('config.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f050c65-58a0-4373-90f2-09bb29557cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e09b9541-080d-4884-a16d-b83acad6ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = ISICApi(username=None, password=None)\n",
    "data_path = data[\"data_folder\"]\n",
    "# num_imgs = data[\"num_imgs\"]\n",
    "# for test I change it to 100, uncomment the above line to have 25000 image\n",
    "num_imgs = 200\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "imageList = []\n",
    "count = 0\n",
    "while len(imageList) < num_imgs:\n",
    "    if count == 0:\n",
    "        temp = api.getJson('images/?limit=' + str(num_imgs) +'&offset=0&sort=name')\n",
    "        imageList = temp['results']\n",
    "        next_page = temp['next'].split(\"images\")[1]\n",
    "    else:\n",
    "        temp = api.getJson('images' + next_page)\n",
    "        imageList = imageList + temp['results']\n",
    "        next_page = temp['next'].split(\"images\")[1]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4b4430f-f504-4fb1-a885-dfbdd3580948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for 200 images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d17518a5694cf4970d963a162c3929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%            \n",
    "print('Fetching metadata for %s images' % len(imageList))\n",
    "imageDetails = []\n",
    "for image in tqdm(imageList):\n",
    "    # Fetch the full image details\n",
    "    imageDetail = api.getJson('images/%s' % image['isic_id'])\n",
    "    imageDetails.append(imageDetail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20c24987-a6f0-4daf-a082-0d63d4beb812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing metadata to CSV: meta.csv\n"
     ]
    }
   ],
   "source": [
    "# Determine the union of all image metadata fields\n",
    "metadataFields = set(\n",
    "        field\n",
    "        for imageDetail in imageDetails\n",
    "        for field in imageDetail['metadata']['clinical'].keys()\n",
    "    )\n",
    "\n",
    "\n",
    "metadataFields = ['isic_id'] + sorted(metadataFields)\n",
    "outputFileName = \"meta\"\n",
    "#%%\n",
    "outputFilePath = os.path.join(data_path, outputFileName)\n",
    "# Write the metadata to a CSV\n",
    "print('Writing metadata to CSV: %s' % outputFileName+'.csv')\n",
    "with open(outputFilePath+'.csv', 'w') as outputStream:\n",
    "    csvWriter = csv.DictWriter(outputStream, metadataFields)\n",
    "    csvWriter.writeheader()\n",
    "    for imageDetail in imageDetails:\n",
    "        rowDict = imageDetail['metadata']['clinical'].copy()\n",
    "        rowDict['isic_id'] = imageDetail['isic_id']\n",
    "        csvWriter.writerow(rowDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d2db93-79dd-451c-9fc3-d3bfedd8555d",
   "metadata": {},
   "source": [
    "# 01_download_imgs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b713a3b6-3fe6-473f-9f95-98a03460ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from isic_api import ISICApi\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "with open('config.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6698d756-daf0-44a2-8595-e3c9996cb84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 50 images\n",
      "Downloading 50 images\n",
      "Downloading 50 images\n",
      "Downloading 50 images\n",
      "Downloading 50 images\n"
     ]
    }
   ],
   "source": [
    "api = ISICApi(username=None, password=None)\n",
    "data_path = data[\"data_folder\"]\n",
    "# num_imgs = data[\"num_imgs\"]\n",
    "num_imgs = 200\n",
    "#%%\n",
    "savePath = os.path.join(data_path, 'raw')\n",
    "\n",
    "if not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "start_offset = 0\n",
    "#%%\n",
    "\n",
    "for i in range(int(num_imgs/50)):\n",
    "    if i == 0:\n",
    "        temp = api.getJson('images/?limit=50')\n",
    "        imageList = temp['results']\n",
    "        next_page = temp['next'].split(\"images\")[1]\n",
    "    else:\n",
    "        temp = api.getJson('images' + next_page)\n",
    "        imageList = temp['results']\n",
    "        next_page = temp['next'].split(\"images\")[1]\n",
    "    print('Downloading %s images' % len(imageList))\n",
    "    \n",
    "    for image in imageList:\n",
    "        url = image['files']['full']['url']\n",
    "        img_data = requests.get(url).content\n",
    "        imageFileOutputPath = os.path.join(savePath, '%s.jpg' % image['isic_id'])\n",
    "        with open(imageFileOutputPath, 'wb') as imageFileOutputStream:\n",
    "            imageFileOutputStream.write(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c1cfea-0136-4e4d-9847-d927833e9cf8",
   "metadata": {},
   "source": [
    "# 02_sort_imgs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be74b10b-d626-4d11-86b8-a364b61a2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "from os.path import join as oj\n",
    "from isic_api import ISICApi\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import json\n",
    "import csv\n",
    "with open('config.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af6b989f-eb18-49d2-b816-d376134de7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = data[\"data_folder\"]\n",
    "img_path = os.path.join(data_path, \"raw\")\n",
    "processed_path = os.path.join(data_path, \"processed\")\n",
    "segmentation_path = os.path.join(data_path, \"segmentation\")\n",
    "benign_path = os.path.join(processed_path, \"no_cancer\")\n",
    "malignant_path = os.path.join(processed_path, \"cancer\")\n",
    "os.makedirs(processed_path,exist_ok = True)\n",
    "os.makedirs(benign_path,exist_ok = True)\n",
    "os.makedirs(segmentation_path,exist_ok = True)\n",
    "os.makedirs(malignant_path,exist_ok = True)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a5fe3440-4391-4b62-8ea1-243ca59233c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_meta = []\n",
    "from PIL import Image\n",
    "with open(oj(data_path, \"meta.csv\"), newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    next(spamreader)\n",
    "    for row in spamreader:\n",
    "        list_of_meta.append(row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a9d80613-7cfb-4288-959f-c837439d05e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "list_benign_files = []\n",
    "for line in list_of_meta:\n",
    "    if len(line) > 0 and line[4] == 'benign':\n",
    "        list_benign_files.append(line[0] + \".jpg\")\n",
    "list_mal_files = []\n",
    "for line in list_of_meta:\n",
    "    if len(line) > 0 and line[4] == 'malignant':\n",
    "        list_mal_files.append(line[0] + \".jpg\")\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "88da17ae-5e80-47ba-be0b-1650abe7b753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 26.05it/s]\n",
      "172it [00:09, 18.38it/s] \n"
     ]
    }
   ],
   "source": [
    "def resize_and_save(my_list, my_folder):\n",
    "    for i,file_name in tqdm(enumerate(my_list)):\n",
    "        try:\n",
    "            img = cv2.imread(oj(img_path, file_name))\n",
    "            resized_img = cv2.resize(img, (299, 299))  # Resize the image to (299, 299)\n",
    "            cv2.imwrite(oj(my_folder, file_name), resized_img)\n",
    "        except:\n",
    "            print(file_name)\n",
    "resize_and_save(list_mal_files, malignant_path)\n",
    "resize_and_save(list_benign_files, benign_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78150127-a4c1-4730-b43b-caad0f910f7e",
   "metadata": {},
   "source": [
    "# 03_calculate_pretrained.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "948bf39b-bf8d-4f95-9894-41cb432fd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pickle as pkl\n",
    "from os.path import join as oj\n",
    "import os\n",
    "from torch.utils.data import Subset\n",
    "import csv\n",
    "import numpy as np\n",
    "sys.path.append('../../src/')\n",
    "from skimage.morphology import dilation\n",
    "import cd\n",
    "from shutil import copyfile\n",
    "from os.path import join as oj\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from skimage.color import rgb2gray\n",
    "import torchvision.models as models\n",
    "from torch import nn    \n",
    "from torch.nn import AdaptiveAvgPool2d\n",
    "import json\n",
    "with open('config.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5156fbe8-92da-47cf-bdc4-cae667c4f953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 173/173 [00:00<00:00, 179.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 187.19it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = data[\"data_folder\"]\n",
    "processed_path = os.path.join(data_path, \"processed\")\n",
    "benign_path = os.path.join(processed_path, \"no_cancer\")\n",
    "malignant_path = os.path.join(processed_path, \"cancer\")\n",
    "feature_path = os.path.join(data_path, \"calculated_features\")\n",
    "segmentation_path = os.path.join(data_path, \"segmentation\")\n",
    "os.makedirs(feature_path,exist_ok = True)\n",
    "#%%\n",
    "# used for converting to the range VGG16 is used to\n",
    "mean = np.asarray([0.485, 0.456, 0.406])\n",
    "std = np.asarray([0.229, 0.224, 0.225])\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "#%%\n",
    "\n",
    "\n",
    "list_of_img_names = os.listdir(benign_path)\n",
    "\n",
    "\n",
    "model = models.vgg16(pretrained=True).to(device).eval()\n",
    "\n",
    "img_features = np.empty((len(list_of_img_names), 25088))\n",
    "cd_features = -np.ones((len(list_of_img_names), 2, 25088)) # rel, irrel\n",
    "avg_layer = torch.nn.AdaptiveAvgPool2d((7,7))\n",
    "from skimage.morphology import square\n",
    "my_square = square(20)\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(list_of_img_names))):\n",
    "        if not(list_of_img_names[i].startswith('.')):\n",
    "            img = Image.open(oj(benign_path, list_of_img_names[i]))\n",
    "            img_torch = torch.from_numpy(((np.asarray(img)/255.0 -mean)/std).swapaxes(0,2).swapaxes(1,2))[None,:].cuda().float()\n",
    "            img.close()\n",
    "            img_features[i] = avg_layer(model.features(img_torch)).view(-1).cpu().numpy()\n",
    "            if os.path.isfile(oj(segmentation_path, list_of_img_names[i])):\n",
    "                seg = Image.open(oj(segmentation_path, list_of_img_names[i]))\n",
    "                blob =  dilation((np.asarray(seg)[:,:, 0] > 100).astype(np.uint8),my_square).astype(np.float32)\n",
    "                \n",
    "                rel, irrel =cd.cd_vgg_features(blob, img_torch, model)\n",
    "                cd_features[i, 0] = rel[0].cpu().numpy()\n",
    "                cd_features[i, 1] = irrel[0].cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "with open(oj(feature_path, \"not_cancer.npy\"), 'wb') as f:\n",
    "    np.save(f, img_features)\n",
    "with open(oj(feature_path, \"not_cancer_cd.npy\"), 'wb') as f:\n",
    "    np.save(f, cd_features)\n",
    " \n",
    "\n",
    "\n",
    "list_of_img_names = os.listdir(malignant_path)\n",
    "img_features = np.empty((len(list_of_img_names), 25088))\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(list_of_img_names))):\n",
    "        if not(list_of_img_names[i].startswith('.')):\n",
    "            img = Image.open(oj(malignant_path, list_of_img_names[i]))\n",
    "            img_torch = torch.from_numpy(((np.asarray(img)/255.0 -mean)/std).swapaxes(0,2).swapaxes(1,2))[None,:].cuda().float()\n",
    "            img.close()\n",
    "            img_features[i] = avg_layer(model.features(img_torch)).view(-1).cpu().numpy()\n",
    "with open(oj(feature_path, \"cancer.npy\"), 'wb') as f:\n",
    "    np.save(f, img_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e4c530-3062-4313-829a-29c0917046ca",
   "metadata": {},
   "source": [
    "# train_saliency.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "85c23532-2298-4656-b47c-487c4470cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from os.path import join as oj\n",
    "\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from numpy.random import randint\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import copy\n",
    "sys.path.append('../../src/')\n",
    "import gc\n",
    "from score_funcs import  gradient_sum\n",
    "import json\n",
    "with open('config.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1d950101-0c25-4f14-bda9-1b106348d1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../models/ISIC_saliency_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ida01/mirzaei/anaconda3/envs/CDEP/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ida01/mirzaei/anaconda3/envs/CDEP/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(data[\"model_folder\"], \"ISIC_saliency_new\")\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "print(model_path)\n",
    "data_path =data[\"data_folder\"]\n",
    "\n",
    "seg_path  = oj(data_path, \"segmentation\")\n",
    "not_cancer_path = oj(data_path, \"processed/no_cancer\")\n",
    "cancer_path = oj(data_path, \"processed/cancer\")\n",
    " \n",
    " \n",
    "mean = np.asarray([0.485, 0.456, 0.406])\n",
    "std = np.asarray([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "description='PyTorch MNIST Example'\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "momentum = 0.9\n",
    "seed = 42\n",
    "lr = 1e-5\n",
    "regularizer_rate = 0.0\n",
    "device = torch.device(0)\n",
    "torch.manual_seed(seed);\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "model.classifier[-1] = nn.Linear(4096, 2)\n",
    "model = model.to(device)\n",
    "params_to_update = model.classifier.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "19a3d2fd-78a3-4feb-b942-e61489b513ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_folder(path):\n",
    "    list_files= os.listdir(path)\n",
    "    num_files = len(list_files)\n",
    "    imgs_np = np.empty((num_files,  299, 299,3))\n",
    "    for i in tqdm(range(num_files)):\n",
    "        try:\n",
    "            img = Image.open(oj(path, list_files[i]))\n",
    "            imgs_np[i] = np.asarray(img)/255.0\n",
    "            \n",
    "            img.close()\n",
    "        except:\n",
    "            print(i)\n",
    "    return imgs_np\n",
    "\n",
    "def load_seg(path, orig_path):\n",
    "    list_files= os.listdir(orig_path)\n",
    "    num_files = len(list_files)\n",
    "    imgs_np = np.zeros((num_files,  299, 299), dtype = bool)\n",
    "    for i in tqdm(range(num_files)):\n",
    "        if os.path.isfile(oj(path,  list_files[i])):\n",
    "            img = Image.open(oj(path, list_files[i]))\n",
    "            imgs_np[i] = np.asarray(img)[:,:,0] > 100\n",
    "            img.close()\n",
    "    return imgs_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d286473d-a27e-45cd-96a7-c3683565e135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 613.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████████████████████████████████▋                                                                                                                       | 55/173 [00:00<00:00, 548.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 173/173 [00:00<00:00, 541.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 173/173 [00:00<00:00, 178810.89it/s]\n"
     ]
    }
   ],
   "source": [
    "cancer_set = load_folder(cancer_path)\n",
    "cancer_set -= mean[None, None, :]\n",
    "cancer_set /= std[None, None, :]\n",
    "not_cancer_set = load_folder(not_cancer_path)\n",
    "not_cancer_set -= mean[None, None, :]\n",
    "not_cancer_set /= std[None, None, :]\n",
    "seg_set = load_seg(seg_path, not_cancer_path)\n",
    "\n",
    "cancer_targets = np.ones((cancer_set.shape[0])).astype(np.int64)\n",
    "not_cancer_targets = np.zeros((not_cancer_set.shape[0])).astype(np.int64)\n",
    "not_cancer_dataset = TensorDataset(torch.from_numpy(not_cancer_set.swapaxes(1,3).swapaxes(2,3)).float(), torch.from_numpy(not_cancer_targets),torch.from_numpy(seg_set))\n",
    "del not_cancer_set\n",
    "del seg_set\n",
    "\n",
    "cancer_dataset = TensorDataset(torch.from_numpy(cancer_set.swapaxes(1,3).swapaxes(2,2)).float(), torch.from_numpy(cancer_targets),torch.from_numpy(np.zeros((len(cancer_set), 299, 299), dtype = bool)))\n",
    "del cancer_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fe118afe-0255-4ba7-8a81-047e07665d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "complete_dataset = ConcatDataset((not_cancer_dataset, cancer_dataset ))\n",
    "num_total = len(complete_dataset)\n",
    "num_train = int(0.8 * num_total)\n",
    "num_val = int(0.1 * num_total)\n",
    "num_test = num_total - num_train - num_val\n",
    "torch.manual_seed(seed);\n",
    "train_dataset, test_dataset, val_dataset= torch.utils.data.random_split(complete_dataset, [num_train, num_test, num_val])\n",
    "datasets = {'train' : train_dataset, 'test':test_dataset, 'val': val_dataset}\n",
    "dataset_sizes = {'train' : len(train_dataset), 'test':len(test_dataset), 'val': len(val_dataset)}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test','val']}\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "cancer_ratio =len(cancer_dataset)/len(complete_dataset)\n",
    "\n",
    "\n",
    "not_cancer_ratio = 1- cancer_ratio\n",
    "cancer_weight = 1/cancer_ratio\n",
    "not_cancer_weight = 1/ not_cancer_ratio\n",
    "weights = np.asarray([not_cancer_weight, cancer_weight])\n",
    "weights /= weights.sum()\n",
    "weights = torch.tensor(weights).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight = weights.double().float())\n",
    "\n",
    "\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c49a096d-1230-44d5-bb9f-7fb6025afb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    val_loss_history = []\n",
    "    train_loss_history = []\n",
    "    \n",
    "    train_acc_history = []\n",
    "    train_cd_history= []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10.0\n",
    "    patience = 3\n",
    "    cur_patience = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                optimizer.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_loss_cd = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels, seg) in tqdm(enumerate(dataloaders[phase])):\n",
    "    \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                seg = seg.to(device)\n",
    "                \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # need to do calc beforehand because we do need the gradients\n",
    "                    if phase == 'train' and regularizer_rate !=0:\n",
    "                        inputs.requires_grad = True\n",
    "                        add_loss = gradient_sum(inputs, labels, seg, model, criterion)  \n",
    "                        if add_loss!=0:\n",
    "                            (regularizer_rate*add_loss).backward()\n",
    "                            optimizer.step()\n",
    "                        #print(torch.cuda.memory_allocated()/(np.power(10,9)))\n",
    "                        optimizer.zero_grad()   \n",
    "                        running_loss_cd +=add_loss.item() * inputs.size(0)\n",
    "     \n",
    "                        #inputs.require_grad = False\n",
    "                   \n",
    "                    \n",
    "                         \n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        (loss).backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_cd_loss = running_loss_cd / dataset_sizes[phase]\n",
    "       \n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "  \n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} CD Loss : {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_cd_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc.item())\n",
    "                val_loss_history.append(epoch_loss)\n",
    "            if phase == 'train':\n",
    "                train_loss_history.append(epoch_loss)\n",
    "                train_cd_history.append(epoch_cd_loss)\n",
    "                train_acc_history.append(epoch_acc.item())\n",
    "                \n",
    "\n",
    "                \n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "            \n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    cur_patience = 0\n",
    "                else:\n",
    "                    cur_patience+=1\n",
    "        if cur_patience >= patience:\n",
    "            break\n",
    "             \n",
    "\n",
    " \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "\n",
    "  \n",
    "    hist_dict = {}\n",
    "    hist_dict['val_acc_history'] = val_acc_history\n",
    "    hist_dict['val_loss_history'] = val_loss_history\n",
    "    \n",
    "    hist_dict['train_acc_history'] = train_acc_history\n",
    "\n",
    "    hist_dict['train_loss_history'] = val_loss_history\n",
    "    hist_dict['train_cd_history'] = train_cd_history\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model,hist_dict \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d6edde9f-07e6-4d55-baa8-ea8c41f5a4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6560 Acc: 0.7838 CD Loss : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:00, 15.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6661 Acc: 0.9444 CD Loss : 0.0000\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:01,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6310 Acc: 0.8378 CD Loss : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:00, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6564 Acc: 0.9444 CD Loss : 0.0000\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:01,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6421 Acc: 0.8311 CD Loss : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:00, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6507 Acc: 0.9444 CD Loss : 0.0000\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:01,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5988 Acc: 0.8581 CD Loss : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:00, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6492 Acc: 0.9444 CD Loss : 0.0000\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:01,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5592 Acc: 0.8784 CD Loss : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:00, 15.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6388 Acc: 0.9444 CD Loss : 0.0000\n",
      "Training complete in 0m 7s\n",
      "Best val loss: 0.638806\n"
     ]
    }
   ],
   "source": [
    "model, hist_dict = train_model(model, dataloaders, criterion, optimizer_ft, num_epochs=epochs)\n",
    "pid = ''.join([\"%s\" % randint(0, 9) for num in range(0, 20)])\n",
    "torch.save(model.classifier.state_dict(),oj(model_path, pid + \".pt\"))\n",
    "\n",
    "hist_dict['pid'] = pid\n",
    "hist_dict['regublarizer_rate'] = regularizer_rate\n",
    "hist_dict['seed'] = seed\n",
    "hist_dict['batch_size'] = batch_size\n",
    "hist_dict['learning_rate'] = lr\n",
    "hist_dict['momentum'] = momentum\n",
    "pkl.dump(hist_dict, open(os.path.join(model_path , pid +  '.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce0504a-0de4-4def-bd03-93e2c924207d",
   "metadata": {},
   "source": [
    "# train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "665c737f-d29d-4857-84c0-0d2b2156de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import os\n",
    "import argparse\n",
    "from numpy.random import randint\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "sys.path.append('../../src')\n",
    "import utils\n",
    "import cd\n",
    "import json\n",
    "torch.backends.cudnn.deterministic = True #this makes results reproducible. \n",
    "with open('config.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a17e9ece-c150-463c-bff5-b3121d20f197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ida01/mirzaei/anaconda3/envs/CDEP/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ida01/mirzaei/anaconda3/envs/CDEP/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(data[\"model_folder\"], \"ISIC_new\")\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "dataset_path =os.path.join(data[\"data_folder\"],\"calculated_features\")\n",
    "\n",
    " \n",
    "# Training settings\n",
    "description='ISIC Skin cancer for CDEP'\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "num_epochs = epochs\n",
    "lr = 1e-2\n",
    "momentum = 0.9\n",
    "seed = 42\n",
    "regularizer_rate = 0.0\n",
    "device = torch.device(0)\n",
    "\n",
    "torch.manual_seed(seed);\n",
    "model = models.vgg16(pretrained=True)\n",
    "model.classifier[-1] = nn.Linear(4096, 2)\n",
    "model = model.classifier.to(device)\n",
    "datasets, weights = utils.load_precalculated_dataset(dataset_path)\n",
    "if regularizer_rate ==-1: # -1 means that we train only on data with no patches\n",
    "    datasets['train'] = datasets['train_no_patches']\n",
    "\n",
    "dataset_sizes= {x:len(datasets[x]) for x in datasets.keys()}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in datasets.keys()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weights = torch.tensor(weights).to(device)\n",
    "\n",
    "params_to_update = model.parameters()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight = weights.double().float())\n",
    "\n",
    "\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c39ce068-2ea3-4822-9f50-3510237edda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    val_loss_history = []\n",
    "    train_loss_history = []\n",
    "    \n",
    "    train_acc_history = []\n",
    "    train_cd_history= []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1000.0\n",
    "    patience = 3\n",
    "    cur_patience = 0\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                optimizer.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_loss_cd = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels, cd_features) in tqdm(enumerate(dataloaders[phase])):\n",
    "    \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                cd_features = cd_features.to(device)\n",
    "                \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                    \n",
    "                        add_loss = torch.zeros(1,).cuda()\n",
    "                        if regularizer_rate > 0:\n",
    "                        \n",
    "                            mask  = (cd_features[:, 0,0] != -1).bool()\n",
    "                            if mask.any():\n",
    "                                rel, irrel = cd.cd_vgg_classifier(cd_features[:,0], cd_features[:,1], inputs, model)\n",
    "                   \n",
    "                                cur_cd_loss = torch.nn.functional.softmax(torch.stack((rel[:,0].masked_select(mask),irrel[:,0].masked_select(mask)), dim =1), dim = 1)[:,0].mean() \n",
    "                                cur_cd_loss +=torch.nn.functional.softmax(torch.stack((rel[:,1].masked_select(mask),irrel[:,1].masked_select(mask)), dim =1), dim = 1)[:,0].mean() \n",
    "                                add_loss = cur_cd_loss/2\n",
    "\n",
    "                        (loss+regularizer_rate*add_loss).backward()\n",
    "                        # print how much memory is used\n",
    "                        #print(torch.cuda.memory_allocated()/(np.power(10,9)))\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_loss_cd +=add_loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_cd_loss = running_loss_cd / dataset_sizes[phase]\n",
    "       \n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "  \n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} CD Loss : {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_cd_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc.item())\n",
    "                val_loss_history.append(epoch_loss)\n",
    "            if phase == 'train':\n",
    "                train_loss_history.append(epoch_loss)\n",
    "                train_cd_history.append(epoch_cd_loss)\n",
    "                train_acc_history.append(epoch_acc.item())\n",
    "                \n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "            \n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    cur_patience = 0\n",
    "                else:\n",
    "                    cur_patience+=1\n",
    "        if cur_patience >= patience:\n",
    "            break\n",
    "             \n",
    "                \n",
    "\n",
    " \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "    hist_dict = {}\n",
    "    hist_dict['val_acc_history'] = val_acc_history\n",
    "    hist_dict['val_loss_history'] = val_loss_history\n",
    "    hist_dict['train_acc_history'] = train_acc_history\n",
    "    hist_dict['train_loss_history'] = val_loss_history\n",
    "    hist_dict['train_cd_history'] = train_cd_history\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model,hist_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0b76fa2e-db53-4dd2-84e2-6b8c0b8ad362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 28.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: nan Acc: 0.6216 CD Loss : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: nan Acc: 0.9444 CD Loss : 0.0000\n",
      "Epoch 1/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [00:00, 32.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: nan Acc: 0.9324 CD Loss : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: nan Acc: 0.9444 CD Loss : 0.0000\n",
      "Epoch 2/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [00:00, 29.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: nan Acc: 0.9324 CD Loss : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: nan Acc: 0.9444 CD Loss : 0.0000\n",
      "Training complete in 0m 1s\n",
      "Best val loss: 1000.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, hist_dict = train_model(model, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs)\n",
    "\n",
    "hist_dict['AUC (no patches)'],hist_dict['F1 score (no patches)'] =utils.get_auc_f1(model, datasets['test_no_patches'])\n",
    "\n",
    "hist_dict['AUC (patches)'],hist_dict['F1 score (patches)'] =utils.get_auc_f1(model, datasets['test'])\n",
    "\n",
    "\n",
    "\n",
    "pid = ''.join([\"%s\" % randint(0, 9) for num in range(0, 20)])\n",
    "#torch.save(model.state_dict(),oj(model_path, pid + \".pt\"))\n",
    "\n",
    "hist_dict['pid'] = pid\n",
    "hist_dict['regularizer_rate'] = regularizer_rate\n",
    "hist_dict['seed'] = seed\n",
    "hist_dict['batch_size'] = batch_size\n",
    "hist_dict['learning_rate'] = lr\n",
    "hist_dict['momentum'] = momentum\n",
    "pkl.dump(hist_dict, open(os.path.join(model_path , pid +  '.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12109da8-1224-4704-93e4-071b27eb4f41",
   "metadata": {},
   "source": [
    "# 04_train_all.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73885fba-677b-40a6-9f65-79319e0e3995",
   "metadata": {},
   "source": [
    "you cant run this in notebook.\n",
    "first you should change train_saliency.py files base in what I write in this notebook and then run that from terminal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CDEP",
   "language": "python",
   "name": "cdep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
